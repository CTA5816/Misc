{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook analyzes a single recording of EMG data from a test subject's biceps. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import and Format Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = '/home/cta/Documents/College/Skywalker Legacy/Sample Data/simple_emg_test.txt' # File containing raw EMG readings\n",
    "df = pd.read_csv(in_data, header=4) # Read file and extract relevant data\n",
    "emg_data = df[\" EXG Channel 0\"]\n",
    "emg_data.rename({\" EXG Channel 0\":\"c0\"})\n",
    "emg_data = emg_data.to_frame('c0')\n",
    "time = np.linspace(1/200,10756/200,10756) # Add time series based on pre-existing knowledge about data properties\n",
    "emg_data['time'] = time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the EMG data looks like before filtration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (25,10)\n",
    "plt.plot(emg_data['time'], emg_data['c0'])\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"Potential Difference (uV)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 200 # Sample rate = 200 Hz. Pre-existing knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scipy-cookbook.readthedocs.io/items/ButterworthBandpass.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a bandpass filter to exclude low- and high-frequency components\n",
    "\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize bandpass filter, run EMG data through it, and add result to dataframe\n",
    "lowcut = 5\n",
    "highcut = 50\n",
    "emg_butter = butter_bandpass_filter(emg_data['c0'],lowcut,highcut,fs,order=2)\n",
    "emg_data['c0_filtered'] = emg_butter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(emg_data['time'], emg_data['c0_filtered'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://neurobb.com/t/openbci-why-are-1-50hz-bandpass-and-60hz-notch-filters-both-applied-by-default/23/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Extract Features and Classify Segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates root mean square feature for a given data segment\n",
    "def calc_rms(data):\n",
    "    sq_sum = 0\n",
    "    for i in range(0, len(data)):\n",
    "        sq_sum += data[i]**2\n",
    "    sq_sum /= len(data)\n",
    "    sq_sum **= (1/2)\n",
    "    return sq_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates waveform length feature (as described in several articles on EMG) for a given data segment\n",
    "def calc_wvlen(data):\n",
    "    wv_len = 0\n",
    "    for i in range(1,len(data)):\n",
    "        wv_len += abs(data[i]-data[i-1])\n",
    "    return wv_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label dataset based on pre-existing measurements (the muscle was either clenched or relaxed. It started relaxed, was clenched at t = 25.13 s, and relaxed again at t = 39.7 s)\n",
    "t_clench = 25.13\n",
    "t_clench -= 0.6 # I'm fudging the data a little because I don't think we labeled it right. Obviously, this is bad practice in real situations\n",
    "t_relax = 39.7\n",
    "t_stop = 53.97\n",
    "offset = emg_data['time'].to_numpy()[-1] - t_stop\n",
    "t_stop_true = t_stop+offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_stop_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point generating function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed the \"ambiguous\" classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in a start time and an end time (bounds) and returns the EMG data over that time segment. If no bounds are given, it generates some at random based on the window size.\n",
    "def gen_point(emg_data,bounds=None,w_size=50, return_bounds=False):\n",
    "    if bounds == None:\n",
    "        t_start = math.floor(random.random()*(len(emg_data)-w_size+1)) # Generates number in range [0,10706]\n",
    "        bounds = (t_start,t_start+w_size-1)\n",
    "    time_seg = emg_data['time'][bounds[0]:bounds[1]+1].to_numpy()\n",
    "    emg_seg = emg_data['c0_filtered'][bounds[0]:bounds[1]+1].to_numpy()\n",
    "    \n",
    "    #label = 'ambiguous'\n",
    "    label = 'error'\n",
    "    if bounds[1]>t_stop_true*fs:\n",
    "        label = 'out_of_bounds'\n",
    "    elif bounds[1]<t_clench*fs or bounds[1]>t_relax*fs: # If the window is outside of the muscle activation time, label it\n",
    "        label = 'relax'\n",
    "    elif t_clench*fs<=bounds[1] and bounds[1]<=t_relax*fs: # If the window is within the muscle activation time, label it\n",
    "        label = 'active'\n",
    "        \n",
    "    if label == 'error':\n",
    "        print('error')\n",
    "    if return_bounds:   \n",
    "        return emg_seg, label, bounds\n",
    "    else:\n",
    "        return emg_seg, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"figure.figsize\"] = (25,10)\n",
    "plt.plot(emg_data['time'], emg_data['c0_filtered'])\n",
    "plt.axvline(x=t_clench,color='red')\n",
    "plt.axvline(x=t_relax,color='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real-deal code that does ML on this dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General functions for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizes a given array based on its own elements\n",
    "def norm_arr_simple(arr,yardstick=None):\n",
    "    arr = np.array(arr)\n",
    "    if yardstick is None:\n",
    "        yardstick = max(abs(arr))\n",
    "    new_arr = np.empty(np.shape(arr))\n",
    "    for i in range(0,len(arr)):\n",
    "        new_arr[i] = arr[i]/yardstick\n",
    "    return new_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a dataset and an array of functions that compute features from datasets of that type, computes normalized features for the given dataset\n",
    "def extract_norm_features(data,f_arr,ys_arr=None):\n",
    "    data_features = np.empty((len(data),len(f_arr)))\n",
    "    for i in range(0,len(data)):\n",
    "        for j in range(0,len(f_arr)):\n",
    "            data_features[i][j] = f_arr[j](data[i])\n",
    "    for i in range(0,len(data_features[0])):\n",
    "        if ys_arr is None:\n",
    "            data_features[:,i] = norm_arr_simple(data_features[:,i])\n",
    "        else:\n",
    "            data_features[:,i] = norm_arr_simple(data_features[:,i],yardstick=ys_arr[i])\n",
    "    return data_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gets points for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get points for classification\n",
    "\n",
    "ws = 100 # window size (units of 5 ms; ws = 100 --> window size of 0.5 seconds)\n",
    "n_points = 96 # number of points\n",
    "\n",
    "X = np.zeros((n_points,ws))\n",
    "y = np.empty(n_points,dtype=object)\n",
    "bounds = np.empty((n_points,2))\n",
    "\n",
    "for i in range(0,n_points): # generates random points of the given window size\n",
    "    emg_seg, label, b = gen_point(emg_data,w_size=ws,return_bounds=True)\n",
    "    X[i] = emg_seg\n",
    "    y[i] = label\n",
    "    bounds[i] = b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute maximum RMS and waveform length for windows of the chosen size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rms_max = -1\n",
    "for i in range(0,len(emg_data['c0_filtered'])-ws):\n",
    "    new_rms = calc_rms(emg_data['c0_filtered'][i:i+ws].to_numpy())\n",
    "    rms_max = max(rms_max,abs(new_rms))\n",
    "\n",
    "wvlen_max = -1\n",
    "for i in range(0,len(emg_data['c0_filtered'])-ws):\n",
    "    new_wvlen = calc_wvlen(emg_data['c0_filtered'][i:i+ws].to_numpy())\n",
    "    wvlen_max = max(wvlen_max,abs(new_wvlen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=24) # divide into training and testing data\n",
    "\n",
    "# Extract features from raw EMG data and make those the new points\n",
    "f_list = [calc_rms, calc_wvlen]\n",
    "yard_arr = [rms_max, wvlen_max]\n",
    "X_train_points = extract_norm_features(X_train,f_list,ys_arr=yard_arr)\n",
    "X_test_points = extract_norm_features(X_test,f_list,ys_arr=yard_arr)\n",
    "\n",
    "# Convert y_train and y_test from string format (\"relax\", \"ambiguous\", \"active\") to integer format (0,1,2)\n",
    "#num_dict = {\"relax\":0, \"ambiguous\":1,\"active\":2}\n",
    "num_dict = {\"relax\":0,\"active\":1}\n",
    "y_train_int = np.zeros(len(y_train),dtype=int)\n",
    "for i in range(0,len(y_train)):\n",
    "    y_train_int[i] = num_dict[y_train[i]]\n",
    "y_test_int = np.zeros(len(y_test),dtype=int)\n",
    "for i in range(0,len(y_test)):\n",
    "    y_test_int[i] = num_dict[y_test[i]]\n",
    "    \n",
    "# labels points with colors based on their value\n",
    "c_dict = {'relax':'blue','active':'orange','ambiguous':'red'}\n",
    "\n",
    "col_arr_train = np.empty(np.shape(y_train),dtype='object') # labels training points with colors\n",
    "for i in range(0,len(col_arr_train)):\n",
    "    col_arr_train[i] = c_dict[y_train[i]]\n",
    "    \n",
    "col_arr_test = np.empty(np.shape(y_test),dtype='object') # labels test points with colors\n",
    "for i in range(0,len(col_arr_test)):\n",
    "    col_arr_test[i] = c_dict[y_test[i]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1 = svm.LinearSVC().fit(X_train_points,y_train_int) # create classifier based on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifies points in testing data\n",
    "pre = clf_1.predict(X_test_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_1.score(X_test_points,y_test_int) # scores accuracy of classifier on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "42/43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_points = np.append(X_train_points,X_test_points,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_int = np.append(y_train_int,y_test_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot classification results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_decision_regions\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "ax = plot_decision_regions(X_points, y_int, clf=clf_1,colors=\"blue,orange\",X_highlight=X_test_points)\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "ax = plot_decision_regions(X_train_points, y_train_int, clf=clf_1,colors=\"blue,orange\")\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "ax = plot_decision_regions(X_test_points, y_test_int, clf=clf_1,colors=\"blue,orange\")\n",
    "ax.set_xlim([0,1])\n",
    "ax.set_ylim([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run everything repeatedly to find the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = 100 # window size (units of 5 ms; ws = 100 --> window size of 0.5 seconds)\n",
    "n_points = 64 # number of points\n",
    "mean_score = 0\n",
    "n = 10\n",
    "for i in range(0,n):\n",
    "    X = np.zeros((n_points,ws))\n",
    "    y = np.empty(n_points,dtype=object)\n",
    "    bounds = np.empty((n_points,2))\n",
    "\n",
    "    for i in range(0,n_points): # generates random points of the given window size\n",
    "        emg_seg, label, b = gen_point(emg_data,w_size=ws,return_bounds=True)\n",
    "        X[i] = emg_seg\n",
    "        y[i] = label\n",
    "        bounds[i] = b\n",
    "        \n",
    "    rms_max = -1\n",
    "    for i in range(0,len(emg_data['c0_filtered'])-ws):\n",
    "        new_rms = calc_rms(emg_data['c0_filtered'][i:i+ws].to_numpy())\n",
    "        rms_max = max(rms_max,abs(new_rms))\n",
    "\n",
    "    wvlen_max = -1\n",
    "    for i in range(0,len(emg_data['c0_filtered'])-ws):\n",
    "        new_wvlen = calc_wvlen(emg_data['c0_filtered'][i:i+ws].to_numpy())\n",
    "        wvlen_max = max(wvlen_max,abs(new_wvlen))\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=24) # divide into training and testing data\n",
    "\n",
    "    # Extract features from raw EMG data and make those the new points\n",
    "    f_list = [calc_rms, calc_wvlen]\n",
    "    yard_arr = [rms_max, wvlen_max]\n",
    "    X_train_points = extract_norm_features(X_train,f_list,ys_arr=yard_arr)\n",
    "    X_test_points = extract_norm_features(X_test,f_list,ys_arr=yard_arr)\n",
    "\n",
    "    # Convert y_train and y_test from string format (\"relax\", \"ambiguous\", \"active\") to integer format (0,1,2)\n",
    "    #num_dict = {\"relax\":0, \"ambiguous\":1,\"active\":2}\n",
    "    num_dict = {\"relax\":0,\"active\":1}\n",
    "    y_train_int = np.zeros(len(y_train),dtype=int)\n",
    "    for i in range(0,len(y_train)):\n",
    "        y_train_int[i] = num_dict[y_train[i]]\n",
    "    y_test_int = np.zeros(len(y_test),dtype=int)\n",
    "    for i in range(0,len(y_test)):\n",
    "        y_test_int[i] = num_dict[y_test[i]]\n",
    "\n",
    "    # labels points with colors based on their value\n",
    "    c_dict = {'relax':'blue','active':'orange','ambiguous':'red'}\n",
    "\n",
    "    col_arr_train = np.empty(np.shape(y_train),dtype='object') # labels training points with colors\n",
    "    for i in range(0,len(col_arr_train)):\n",
    "        col_arr_train[i] = c_dict[y_train[i]]\n",
    "\n",
    "    col_arr_test = np.empty(np.shape(y_test),dtype='object') # labels test points with colors\n",
    "    for i in range(0,len(col_arr_test)):\n",
    "        col_arr_test[i] = c_dict[y_test[i]]\n",
    "        \n",
    "    clf_1 = svm.LinearSVC().fit(X_train_points,y_train_int) # create classifier based on training data\n",
    "    s = clf_1.score(X_test_points,y_test_int) # scores accuracy of classifier on testing data\n",
    "    mean_score += s/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ws = 100; n_points = 128; mean_score = 0.9279\n",
    "\n",
    "**ws = 100; n_points = 96; mean_score = 0.9219**\n",
    "\n",
    "ws = 100; n_points = 64; mean_score = 0.9364\n",
    "\n",
    "ws = 75; n_points = 128; mean_score = 0.9023\n",
    "\n",
    "ws = 75; n_points = 96; mean_score = 0.8969\n",
    "\n",
    "ws = 75; n_points = 64; mean_score = 0.9000\n",
    "\n",
    "ws = 50; n_points = 128; mean_score = 0.8953\n",
    "\n",
    "ws = 50; n_points = 96; mean_score = 0.8750\n",
    "\n",
    "ws = 50; n_points = 64; mean_score = 0.8591"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
